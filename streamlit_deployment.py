"""
Specific file required only for streamlit prototype deployment
"""

import streamlit as st
import requests
from PIL import Image
import os
import pickle
import matplotlib.pyplot as plt
import time
from io import BytesIO
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from transformers import AutoModelForImageClassification
import torch

from src.config_loaders.inference_config_loader import inference_config_loader
from src.aws_services.s3_service import S3Manager
from src.utils.schema import SavingSchema


@st.cache_resource
def load_model_and_transforms():
    print("Loading configuration and model from S3 Bucket")

    # Load configuration
    config = inference_config_loader(config_path="config/inference_config.json")

    # Download model from S3
    s3_manager = S3Manager(bucket_name=config.bucket_name)
    s3_manager.download_directory(
        s3_prefix=config.s3_model_prefix, local_directory_path=config.local_model_dir
    )

    # Build Model
    model = AutoModelForImageClassification.from_pretrained(config.local_model_dir)
    model.eval()
    transforms_file_path = os.path.join(
        config.local_model_dir, SavingSchema.TRANSFORMS_PKL
    )
    with open(transforms_file_path, "rb") as f:
        _transforms = pickle.load(f)
    return model, _transforms, config.top_n


torch.manual_seed(42)  # fix seed to ensure reproductibility
model, _transforms, top_k = load_model_and_transforms()

# UI
st.set_page_config(page_title="Human Pose Classification", page_icon="üßç")
st.title("üßçHuman Pose Classification App")

# --- Choose input method ---
input_method = st.radio("Choose input method:", ["Image URL", "Upload File"])

image_url = None
uploaded_file = None

if input_method == "Image URL":
    image_url = st.text_input("Enter the image URL:")
elif input_method == "Upload File":
    uploaded_file = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])

# Disable predict button if nothing is provided
button_disabled = (input_method == "Image URL" and not image_url) or (
    input_method == "Upload File" and not uploaded_file
)

if st.button("Predict", disabled=button_disabled):

    with st.spinner("üîÑ Processing in progress... Please wait."):
        start_time = time.time()

        # Load image preview
        try:
            if image_url:
                response = requests.get(image_url, timeout=5)
                response.raise_for_status()
                img = Image.open(BytesIO(response.content)).convert("RGB")
            else:
                img = Image.open(uploaded_file).convert("RGB")
            st.image(img, caption="Input Image", use_container_width=True)
        except Exception as e:
            st.error(f"Error loading image: {e}")
            st.stop()

        # Apply transforms and get prediction
        pixel_values = _transforms(img).unsqueeze(0)
        with torch.no_grad():
            outputs = model(pixel_values)
            probs = torch.softmax(outputs.logits, dim=-1)
            top_probs, top_indices = torch.topk(probs, k=top_k, dim=-1)
            top_probs = top_probs.squeeze(0).tolist()
            top_indices = top_indices.squeeze(0).tolist()
            top_labels = [model.config.id2label[idx] for idx in top_indices]

        if top_labels and top_probs:
            st.success("‚úÖ Prediction completed successfully.")

            # Histogram of top probabilities
            st.subheader("Top Predictions")
            fig, ax = plt.subplots()
            ax.bar(top_labels, top_probs)
            ax.set_xlabel("Probability")
            ax.set_ylabel("Class")
            ax.set_ylim(0, 1)
            plt.xticks(rotation=45, ha="right")
            st.pyplot(fig)

            # Display calculation time
            prediction_time = int((time.time() - start_time) * 1000)
            st.caption(f"‚è± Prediction time: {prediction_time} ms")

        else:
            st.warning("‚ö†Ô∏è No predictions returned.")
